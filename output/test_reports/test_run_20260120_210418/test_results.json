{
  "timestamp": "2026-01-20T21:08:00.823407",
  "total_tests": 26,
  "passed": 26,
  "failed": 0,
  "skipped": 0,
  "results": [
    {
      "test_name": "tests/test_algo_handling.py::test_get_algo_names_column",
      "outcome": "passed",
      "duration": 0.0033452510833740234,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "Assertion: isinstance(algos, pd.Series)",
          "condition": "isinstance(algos, pd.Series)"
        },
        {
          "description": "len(algos) compares to 5",
          "condition": "len(algos) == 5"
        },
        {
          "description": "list(algos.values) compares to ['LR', 'DT', 'RF', 'CNN', 'TabNet']",
          "condition": "list(algos.values) == ['LR', 'DT', 'RF', 'CNN', 'TabNet']"
        },
        {
          "description": "algos.dtype compares to 'object'",
          "condition": "algos.dtype == 'object'"
        }
      ],
      "success_reason": "All validation criteria satisfied: 4/4 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_algo_handling.py::test_get_algo_names_index",
      "outcome": "passed",
      "duration": 0.0033032894134521484,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "Assertion: isinstance(algos, pd.Series)",
          "condition": "isinstance(algos, pd.Series)"
        },
        {
          "description": "len(algos) compares to 3",
          "condition": "len(algos) == 3"
        },
        {
          "description": "list(algos.values) compares to ['LR', 'DT', 'RF']",
          "condition": "list(algos.values) == ['LR', 'DT', 'RF']"
        }
      ],
      "success_reason": "All validation criteria satisfied: 3/3 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_algo_handling.py::test_get_algo_names_raises",
      "outcome": "passed",
      "duration": 0.0018777847290039062,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [],
      "success_reason": "Test passed - All assertions satisfied",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_algo_handling.py::test_ensure_algo_column",
      "outcome": "passed",
      "duration": 0.0032243728637695312,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "'algo' compares to result1.columns",
          "condition": "'algo' in result1.columns"
        },
        {
          "description": "Assertion: result1.equals(df1)",
          "condition": "result1.equals(df1)"
        },
        {
          "description": "'algo' compares to result2.columns",
          "condition": "'algo' in result2.columns"
        },
        {
          "description": "list(result2['algo'].values) compares to ['LR', 'DT']",
          "condition": "list(result2['algo'].values) == ['LR', 'DT']"
        },
        {
          "description": "result3 compares to None",
          "condition": "result3 is None"
        }
      ],
      "success_reason": "All validation criteria satisfied: 5/5 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_algo_handling.py::test_sanitize_algo_name",
      "outcome": "passed",
      "duration": 0.0013515949249267578,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "result compares to expected",
          "condition": "result == expected"
        },
        {
          "description": "result compares to label",
          "condition": "result == label"
        }
      ],
      "success_reason": "All validation criteria satisfied: 2/2 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_cnn.py::test_cnn_pipeline_full_flow",
      "outcome": "passed",
      "duration": 99.76893448829651,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "1 compares to results",
          "condition": "1 in results"
        },
        {
          "description": "2 compares to results",
          "condition": "2 in results"
        },
        {
          "description": "3 compares to results",
          "condition": "3 in results"
        },
        {
          "description": "5 compares to results",
          "condition": "5 in results"
        },
        {
          "description": "runner.best_config compares to None",
          "condition": "runner.best_config is not None"
        },
        {
          "description": "Assertion: (test_results_dir / 'phase1_config_search' / 'best_config.json').exists()",
          "condition": "(test_results_dir / 'phase1_config_search' / 'best_config.json').exists()"
        },
        {
          "description": "algo compares to found_algos",
          "condition": "algo in found_algos"
        }
      ],
      "success_reason": "All validation criteria satisfied: 7/7 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_dataset_source_flag.py::test_dataset_source_flag",
      "outcome": "passed",
      "duration": 0.02791309356689453,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "'dataset_source' compares to X.columns",
          "condition": "'dataset_source' in X.columns"
        },
        {
          "description": "'dataset_source' compares to X_f.columns",
          "condition": "'dataset_source' not in X_f.columns"
        }
      ],
      "success_reason": "All validation criteria satisfied: 2/2 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_model_aware_profiles.py::test_model_aware_profiles",
      "outcome": "passed",
      "duration": 0.011481761932373047,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "lr_profile[\"apply_scaling\"] compares to True",
          "condition": "lr_profile[\"apply_scaling\"] is True"
        },
        {
          "description": "lr_profile[\"apply_feature_selection\"] compares to True",
          "condition": "lr_profile[\"apply_feature_selection\"] is True"
        },
        {
          "description": "lr_profile[\"apply_resampling\"] compares to True",
          "condition": "lr_profile[\"apply_resampling\"] is True"
        },
        {
          "description": "lr_profile.get(\"use_class_weight\", False) compares to False",
          "condition": "lr_profile.get(\"use_class_weight\", False) is False"
        },
        {
          "description": "\"feature_selection_k\" compares to lr_profile",
          "condition": "\"feature_selection_k\" in lr_profile"
        },
        {
          "description": "Assertion: 10 <= lr_profile[\"feature_selection_k\"] <= 60",
          "condition": "10 <= lr_profile[\"feature_selection_k\"] <= 60"
        },
        {
          "description": "cnn_profile[\"apply_scaling\"] compares to True",
          "condition": "cnn_profile[\"apply_scaling\"] is True"
        },
        {
          "description": "cnn_profile[\"apply_feature_selection\"] compares to False",
          "condition": "cnn_profile[\"apply_feature_selection\"] is False"
        },
        {
          "description": "cnn_profile[\"apply_resampling\"] compares to True",
          "condition": "cnn_profile[\"apply_resampling\"] is True"
        },
        {
          "description": "cnn_profile.get(\"cnn_reshape\", False) compares to True",
          "condition": "cnn_profile.get(\"cnn_reshape\", False) is True"
        },
        {
          "description": "tabnet_profile[\"apply_scaling\"] compares to False",
          "condition": "tabnet_profile[\"apply_scaling\"] is False"
        },
        {
          "description": "tabnet_profile[\"apply_feature_selection\"] compares to False",
          "condition": "tabnet_profile[\"apply_feature_selection\"] is False"
        },
        {
          "description": "tabnet_profile[\"apply_resampling\"] compares to False",
          "condition": "tabnet_profile[\"apply_resampling\"] is False"
        },
        {
          "description": "tabnet_profile[\"use_class_weight\"] compares to True",
          "condition": "tabnet_profile[\"use_class_weight\"] is True"
        },
        {
          "description": "tabnet_profile.get(\"class_weight\") compares to \"balanced\"",
          "condition": "tabnet_profile.get(\"class_weight\") == \"balanced\""
        },
        {
          "description": "tree_profile[\"apply_scaling\"] compares to False",
          "condition": "tree_profile[\"apply_scaling\"] is False"
        },
        {
          "description": "tree_profile[\"apply_feature_selection\"] compares to False",
          "condition": "tree_profile[\"apply_feature_selection\"] is False"
        },
        {
          "description": "tree_profile[\"apply_resampling\"] compares to False",
          "condition": "tree_profile[\"apply_resampling\"] is False"
        },
        {
          "description": "tree_profile[\"use_class_weight\"] compares to True",
          "condition": "tree_profile[\"use_class_weight\"] is True"
        },
        {
          "description": "tree_profile.get(\"class_weight\") compares to \"balanced\"",
          "condition": "tree_profile.get(\"class_weight\") == \"balanced\""
        }
      ],
      "success_reason": "All validation criteria satisfied: 20/20 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_no_data_leakage.py::test_scaler_fit_only_on_train",
      "outcome": "passed",
      "duration": 0.14270448684692383,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "Assertion: pipeline.is_fitted",
          "condition": "pipeline.is_fitted"
        },
        {
          "description": "pipeline.scaler compares to None",
          "condition": "pipeline.scaler is not None"
        },
        {
          "description": "X_test_transformed.shape[0] compares to n_test",
          "condition": "X_test_transformed.shape[0] == n_test"
        },
        {
          "description": "X_test_transformed.shape[1] compares to n_features",
          "condition": "X_test_transformed.shape[1] == n_features"
        },
        {
          "description": "np.abs(test_scaled_mean.mean()) compares to 5.0",
          "condition": "np.abs(test_scaled_mean.mean()) < 5.0"
        }
      ],
      "success_reason": "All validation criteria satisfied: 5/5 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_no_data_leakage.py::test_feature_selector_fit_only_on_train",
      "outcome": "passed",
      "duration": 0.3441581726074219,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "pipeline.feature_selector compares to None",
          "condition": "pipeline.feature_selector is not None"
        },
        {
          "description": "pipeline.selected_features compares to None",
          "condition": "pipeline.selected_features is not None"
        },
        {
          "description": "len(pipeline.selected_features) compares to k_selected",
          "condition": "len(pipeline.selected_features) == k_selected"
        },
        {
          "description": "X_test_transformed.shape[1] compares to k_selected",
          "condition": "X_test_transformed.shape[1] == k_selected"
        },
        {
          "description": "X_test_transformed.shape[0] compares to n_test",
          "condition": "X_test_transformed.shape[0] == n_test"
        }
      ],
      "success_reason": "All validation criteria satisfied: 5/5 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_no_data_leakage.py::test_imputer_fit_only_on_train",
      "outcome": "passed",
      "duration": 0.0878000259399414,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "pipeline.imputer compares to None",
          "condition": "pipeline.imputer is not None"
        },
        {
          "description": "Assertion: not np.isnan(X_test_transformed).any()",
          "condition": "not np.isnan(X_test_transformed).any()"
        },
        {
          "description": "np.abs(test_imputed_values.mean() - train_median_feature0) compares to 30.0",
          "condition": "np.abs(test_imputed_values.mean() - train_median_feature0) < 30.0"
        }
      ],
      "success_reason": "All validation criteria satisfied: 3/3 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_no_data_leakage.py::test_transform_test_no_fitting",
      "outcome": "passed",
      "duration": 0.11924314498901367,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "Assertion: np.array_equal(pipeline.scaler.center_, scaler_center_before)",
          "condition": "np.array_equal(pipeline.scaler.center_, scaler_center_before)"
        },
        {
          "description": "Assertion: np.array_equal(pipeline.scaler.scale_, scaler_scale_before)",
          "condition": "np.array_equal(pipeline.scaler.scale_, scaler_scale_before)"
        }
      ],
      "success_reason": "All validation criteria satisfied: 2/2 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_no_global_fit_regression.py::test_no_global_fit_regression",
      "outcome": "passed",
      "duration": 0.03960013389587402,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "MockPipeline.call_count compares to 2",
          "condition": "MockPipeline.call_count == 2"
        }
      ],
      "success_reason": "All validation criteria satisfied: 1/1 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_no_smote_leakage_phase3.py::test_no_smote_leakage_phase3",
      "outcome": "passed",
      "duration": 0.16848158836364746,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "\"Applying SMOTE before splitting\" compares to caplog.text",
          "condition": "\"Applying SMOTE before splitting\" not in caplog.text"
        },
        {
          "description": "counts[0] compares to counts[1]",
          "condition": "counts[0] == counts[1]"
        },
        {
          "description": "counts[0] compares to 10",
          "condition": "counts[0] > 10"
        },
        {
          "description": "pipeline.smote compares to None",
          "condition": "pipeline.smote is not None"
        }
      ],
      "success_reason": "All validation criteria satisfied: 4/4 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_phase2_outputs.py::test_phase2_outputs",
      "outcome": "passed",
      "duration": 0.060495853424072266,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "Assertion: output_paths[\"preprocessed_data\"].exists()",
          "condition": "output_paths[\"preprocessed_data\"].exists()"
        },
        {
          "description": "Assertion: output_paths[\"feature_names\"].exists()",
          "condition": "output_paths[\"feature_names\"].exists()"
        },
        {
          "description": "Assertion: output_paths[\"summary\"].exists()",
          "condition": "output_paths[\"summary\"].exists()"
        },
        {
          "description": "\"dataset_source\" compares to df.columns",
          "condition": "\"dataset_source\" in df.columns"
        },
        {
          "description": "Assertion: df[\"dataset_source\"].isin([0, 1]).all()",
          "condition": "df[\"dataset_source\"].isin([0, 1]).all()"
        },
        {
          "description": "\"label\" compares to df.columns",
          "condition": "\"label\" in df.columns"
        },
        {
          "description": "\"feature_names\" compares to feature_data",
          "condition": "\"feature_names\" in feature_data"
        },
        {
          "description": "Assertion: \"dataset_source\" in feature_data[\"feature_names\"] or \"dataset_source\" not in df.drop(columns=[\"label",
          "condition": "\"dataset_source\" in feature_data[\"feature_names\"] or \"dataset_source\" not in df.drop(columns=[\"label\"]).columns"
        },
        {
          "description": "\"Phase 2: Apply Best Configuration\" compares to summary_content",
          "condition": "\"Phase 2: Apply Best Configuration\" in summary_content"
        },
        {
          "description": "Assertion: \"dataset_source\" in summary_content or \"Dataset Source Distribution\" in summary_content",
          "condition": "\"dataset_source\" in summary_content or \"Dataset Source Distribution\" in summary_content"
        },
        {
          "description": "\"Stateless preprocessing only\" compares to summary_content",
          "condition": "\"Stateless preprocessing only\" in summary_content"
        }
      ],
      "success_reason": "All validation criteria satisfied: 11/11 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_phase3_cnn_tabnet.py::test_phase3_cnn_tabnet_profiles",
      "outcome": "passed",
      "duration": 0.002136707305908203,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "'cnn_profile' compares to config.preprocessing_profiles",
          "condition": "'cnn_profile' in config.preprocessing_profiles"
        },
        {
          "description": "cnn_profile.get('apply_scaling') compares to True",
          "condition": "cnn_profile.get('apply_scaling') is True"
        },
        {
          "description": "cnn_profile.get('apply_feature_selection') compares to False",
          "condition": "cnn_profile.get('apply_feature_selection') is False"
        },
        {
          "description": "cnn_profile.get('cnn_reshape') compares to True",
          "condition": "cnn_profile.get('cnn_reshape') is True"
        },
        {
          "description": "cnn_profile.get('apply_resampling') compares to True",
          "condition": "cnn_profile.get('apply_resampling') is True"
        },
        {
          "description": "'tabnet_profile' compares to config.preprocessing_profiles",
          "condition": "'tabnet_profile' in config.preprocessing_profiles"
        },
        {
          "description": "tabnet_profile.get('apply_scaling') compares to False",
          "condition": "tabnet_profile.get('apply_scaling') is False"
        },
        {
          "description": "tabnet_profile.get('apply_feature_selection') compares to False",
          "condition": "tabnet_profile.get('apply_feature_selection') is False"
        },
        {
          "description": "tabnet_profile.get('use_class_weight') compares to True",
          "condition": "tabnet_profile.get('use_class_weight') is True"
        },
        {
          "description": "tabnet_profile.get('class_weight') compares to 'balanced'",
          "condition": "tabnet_profile.get('class_weight') == 'balanced'"
        }
      ],
      "success_reason": "All validation criteria satisfied: 10/10 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_phase3_cnn_tabnet.py::test_phase3_model_names",
      "outcome": "passed",
      "duration": 0.0014841556549072266,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "Assertion: 'cnn' in algos_lower or 'CNN' in config.phase3_algorithms",
          "condition": "'cnn' in algos_lower or 'CNN' in config.phase3_algorithms"
        },
        {
          "description": "Assertion: 'tabnet' in algos_lower or 'TabNet' in config.phase3_algorithms",
          "condition": "'tabnet' in algos_lower or 'TabNet' in config.phase3_algorithms"
        }
      ],
      "success_reason": "All validation criteria satisfied: 2/2 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_phase3_cnn_tabnet.py::test_phase3_metrics_df_format",
      "outcome": "passed",
      "duration": 0.003714323043823242,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "'algo' compares to metrics_df_ensured.columns",
          "condition": "'algo' in metrics_df_ensured.columns"
        },
        {
          "description": "list(algos.values) compares to ['LR', 'CNN', 'TabNet']",
          "condition": "list(algos.values) == ['LR', 'CNN', 'TabNet']"
        }
      ],
      "success_reason": "All validation criteria satisfied: 2/2 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_phase3_synthetic.py::test_phase3_synthetic_produces_outputs",
      "outcome": "passed",
      "duration": 5.048553466796875,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "Assertion: results_file.exists()",
          "condition": "results_file.exists()"
        },
        {
          "description": "len(results_df) compares to 0",
          "condition": "len(results_df) > 0"
        },
        {
          "description": "\"model_name\" compares to results_df.columns",
          "condition": "\"model_name\" in results_df.columns"
        },
        {
          "description": "\"f1_score\" compares to results_df.columns",
          "condition": "\"f1_score\" in results_df.columns"
        },
        {
          "description": "len(dimension_scores_df) compares to 0",
          "condition": "len(dimension_scores_df) > 0"
        },
        {
          "description": "\"model_name\" compares to dimension_scores_df.columns",
          "condition": "\"model_name\" in dimension_scores_df.columns"
        },
        {
          "description": "len(report_files) compares to 0",
          "condition": "len(report_files) > 0"
        }
      ],
      "success_reason": "All validation criteria satisfied: 7/7 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_preprocessing_pipeline.py::test_sanitize_numeric_values_removes_inf_and_clips",
      "outcome": "passed",
      "duration": 0.01618194580078125,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "X_sanitized.shape compares to X_df.shape",
          "condition": "X_sanitized.shape == X_df.shape"
        },
        {
          "description": "list(X_sanitized.columns) compares to list(X_df.columns)",
          "condition": "list(X_sanitized.columns) == list(X_df.columns)"
        },
        {
          "description": "inf_count compares to 0",
          "condition": "inf_count == 0"
        },
        {
          "description": "X_sanitized.loc[4, 'feature_2'] compares to q_high_2",
          "condition": "X_sanitized.loc[4, 'feature_2'] <= q_high_2"
        },
        {
          "description": "X_sanitized.loc[5, 'feature_2'] compares to q_low_2",
          "condition": "X_sanitized.loc[5, 'feature_2'] >= q_low_2"
        },
        {
          "description": "finite_sanitized.min() compares to q_low",
          "condition": "finite_sanitized.min() >= q_low"
        },
        {
          "description": "finite_sanitized.max() compares to q_high",
          "condition": "finite_sanitized.max() <= q_high"
        }
      ],
      "success_reason": "All validation criteria satisfied: 7/7 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_preprocessing_pipeline.py::test_sanitize_numeric_values_replace_inf_with_max",
      "outcome": "passed",
      "duration": 0.006304264068603516,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "inf_count compares to 0",
          "condition": "inf_count == 0"
        },
        {
          "description": "X_sanitized.loc[0, 'feature_0'] compares to expected_max_0",
          "condition": "X_sanitized.loc[0, 'feature_0'] == expected_max_0"
        },
        {
          "description": "X_sanitized.loc[1, 'feature_0'] compares to expected_min_0",
          "condition": "X_sanitized.loc[1, 'feature_0'] == expected_min_0"
        },
        {
          "description": "X_sanitized.loc[2, 'feature_1'] compares to expected_max_1",
          "condition": "X_sanitized.loc[2, 'feature_1'] == expected_max_1"
        }
      ],
      "success_reason": "All validation criteria satisfied: 4/4 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_preprocessing_pipeline.py::test_sanitize_numeric_values_abs_cap",
      "outcome": "passed",
      "duration": 0.004284858703613281,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "X_sanitized.values.min() compares to -abs_cap",
          "condition": "X_sanitized.values.min() >= -abs_cap"
        },
        {
          "description": "X_sanitized.values.max() compares to abs_cap",
          "condition": "X_sanitized.values.max() <= abs_cap"
        },
        {
          "description": "X_sanitized.loc[0, 'feature_0'] compares to abs_cap",
          "condition": "X_sanitized.loc[0, 'feature_0'] == abs_cap"
        },
        {
          "description": "X_sanitized.loc[1, 'feature_0'] compares to -abs_cap",
          "condition": "X_sanitized.loc[1, 'feature_0'] == -abs_cap"
        }
      ],
      "success_reason": "All validation criteria satisfied: 4/4 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_preprocessing_pipeline.py::test_sanitize_numeric_values_integration_with_clean_data",
      "outcome": "passed",
      "duration": 0.0215146541595459,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "inf_count compares to 0",
          "condition": "inf_count == 0"
        },
        {
          "description": "np.abs(X_cleaned.loc[2, 'feature_1']) compares to np.abs(q_high_1) * 2",
          "condition": "np.abs(X_cleaned.loc[2, 'feature_1']) <= np.abs(q_high_1) * 2"
        },
        {
          "description": "X_cleaned.shape[0] compares to X_df.shape[0]",
          "condition": "X_cleaned.shape[0] == X_df.shape[0]"
        },
        {
          "description": "X_cleaned.shape[1] compares to X_df.shape[1]",
          "condition": "X_cleaned.shape[1] == X_df.shape[1]"
        }
      ],
      "success_reason": "All validation criteria satisfied: 4/4 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_preprocessing_pipeline.py::test_transform_test_requires_fitted_pipeline",
      "outcome": "passed",
      "duration": 0.024930953979492188,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "Assertion: not pipeline.is_fitted",
          "condition": "not pipeline.is_fitted"
        },
        {
          "description": "Assertion: pipeline.is_fitted",
          "condition": "pipeline.is_fitted"
        },
        {
          "description": "Assertion: isinstance(result, np.ndarray)",
          "condition": "isinstance(result, np.ndarray)"
        },
        {
          "description": "result.shape[0] compares to 10",
          "condition": "result.shape[0] == 10"
        },
        {
          "description": "result.shape[1] compares to 5",
          "condition": "result.shape[1] == 5"
        }
      ],
      "success_reason": "All validation criteria satisfied: 5/5 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_tabnet.py::test_tabnet_pipeline_full_flow",
      "outcome": "passed",
      "duration": 110.46567630767822,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "1 compares to results",
          "condition": "1 in results"
        },
        {
          "description": "2 compares to results",
          "condition": "2 in results"
        },
        {
          "description": "3 compares to results",
          "condition": "3 in results"
        },
        {
          "description": "5 compares to results",
          "condition": "5 in results"
        },
        {
          "description": "runner.best_config compares to None",
          "condition": "runner.best_config is not None"
        },
        {
          "description": "Assertion: (test_results_dir / 'phase1_config_search' / 'best_config.json').exists()",
          "condition": "(test_results_dir / 'phase1_config_search' / 'best_config.json').exists()"
        },
        {
          "description": "algo compares to found_algos",
          "condition": "algo in found_algos"
        }
      ],
      "success_reason": "All validation criteria satisfied: 7/7 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    },
    {
      "test_name": "tests/test_test_transform_is_fold_fitted.py::test_test_transform_is_fold_fitted",
      "outcome": "passed",
      "duration": 0.10102319717407227,
      "input_description": "N/A",
      "output_description": "N/A",
      "input_matrices": [],
      "validation_criteria": [
        {
          "description": "Assertion: not np.isnan(X_test_prep).any()",
          "condition": "not np.isnan(X_test_prep).any()"
        },
        {
          "description": "Assertion: np.isfinite(X_test_prep).all()",
          "condition": "np.isfinite(X_test_prep).all()"
        },
        {
          "description": "Assertion: not np.isnan(X_test_prep_t).any()",
          "condition": "not np.isnan(X_test_prep_t).any()"
        },
        {
          "description": "X_test_prep_t[0, 0] compares to 10.0",
          "condition": "X_test_prep_t[0, 0] == 10.0"
        },
        {
          "description": "X_test_prep_t[1, 0] compares to 10.0",
          "condition": "X_test_prep_t[1, 0] == 10.0"
        }
      ],
      "success_reason": "All validation criteria satisfied: 5/5 passed",
      "failure_reason": "",
      "error_message": "",
      "traceback": ""
    }
  ]
}