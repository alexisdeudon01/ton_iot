# Formules Exactes IRP - M√©moire IRP_FinalADE_v2.0ADE-2-1.pdf

Ce document documente les **formules exactes** et les **features n√©cessaires** pour chaque dimension selon le m√©moire IRP.

---

## üìê Dimension 1: Detection Performance

### M√©triques Calcul√©es

#### 1. Precision (Pr)
**Formule exacte selon m√©moire IRP:**
```
Precision (Pr) = TP / (TP + FP)
```
- **TP**: True Positives
- **FP**: False Positives

#### 2. Recall (Rc)
**Formule exacte selon m√©moire IRP:**
```
Recall (Rc) = TP / (TP + FN)
```
- **TP**: True Positives
- **FN**: False Negatives

#### 3. F1 Score
**Formule exacte selon m√©moire IRP:**
```
F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)
```

**Variant √©quivalent:**
```
F1 = 2 √ó (TP) / (2 √ó TP + FP + FN)
```

#### 4. Accuracy
**Formule exacte selon m√©moire IRP:**
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

### Calcul Multi-Classes (CIC-DDoS2019)

Pour les probl√®mes **multi-classes** avec 11 types d'attaques (CIC-DDoS2019), les m√©triques utilisent **moyenne pond√©r√©e** (`average='weighted'`):

```
Precision_weighted = Œ£ (Precision_i √ó Support_i) / Œ£ Support_i
Recall_weighted = Œ£ (Recall_i √ó Support_i) / Œ£ Support_i
F1_weighted = Œ£ (F1_i √ó Support_i) / Œ£ Support_i
```

O√π:
- `i` = classe (Benign, DNS, LDAP, MSSQL, TFTP, UDP, UDP-Lag, SYN, etc.)
- `Support_i` = nombre d'instances de la classe `i`

### Score Final Dimension 1

**Selon m√©moire IRP, le score Dimension 1 est:**
```
Dimension1_Score = F1_Score_weighted
```

**Normalisation pour comparaison (optionnelle):**
```
Dimension1_Normalized = (F1_Score - F1_min) / (F1_max - F1_min)
```

### Features N√©cessaires Dimension 1

- **Matrice de confusion**: TP, TN, FP, FN (par classe pour multi-classes)
- **Predictions**: `y_pred` (classes pr√©dites)
- **Labels r√©els**: `y_test` (classes r√©elles)
- **Support par classe**: Nombre d'instances par classe

---

## üìê Dimension 2: Resource Efficiency

### M√©triques Mesur√©es

#### 1. Training Time (T_training)
**Mesure:**
```
T_training = T_end - T_start  [secondes]
```
- Mesur√© avec `time.time()` ou `ResourceMonitor`

#### 2. Memory Usage (M_used)
**Mesure:**
```
M_used = M_peak - M_start  [MB]
```
- Mesur√© avec `psutil` via `ResourceMonitor`
- `M_peak`: M√©moire maximale atteinte pendant l'entra√Ænement

### Normalisation

Les m√©triques de ressources suivent le principe **"moins = mieux"**. Pour normaliser en **"plus = mieux"** (score [0,1]):

#### Option 1: Normalisation Inverse (selon m√©moire IRP)
```
normalized_time = 1 / (1 + T_training / T_max)
normalized_memory = 1 / (1 + M_used / M_max)
```

#### Option 2: Normalisation Min-Max Inverse
```
normalized_time = 1 - (T_training - T_min) / (T_max - T_min)
normalized_memory = 1 - (M_used - M_min) / (M_max - M_min)
```

### Score Combin√© Dimension 2

**Formule exacte selon m√©moire IRP:**
```
Dimension2_Score = 0.6 √ó normalized_time + 0.4 √ó normalized_memory
```

**Pond√©rations:**
- **60%**: Training Time (priorit√©)
- **40%**: Memory Usage

### Features N√©cessaires Dimension 2

- **Training Time**: Mesure temporelle pendant `model.fit()`
- **Memory Usage**: Mesure m√©moire (start, peak, used)
- **Normalisation**: N√©cessite T_max, T_min, M_max, M_min de tous les mod√®les

---

## üìê Dimension 3: Explainability

### Composantes

#### 1. Native Interpretability (I_native)

**Valeur binaire selon m√©moire IRP:**
```
I_native = 1.0  si mod√®le a feature_importances_
I_native = 0.0  sinon
```

**Mod√®les avec I_native = 1.0:**
- Decision Tree (`DecisionTreeClassifier.feature_importances_`)
- Random Forest (`RandomForestClassifier.feature_importances_`)

**Mod√®les avec I_native = 0.0:**
- Logistic Regression
- CNN (Convolutional Neural Network)
- TabNet

**Pond√©ration selon m√©moire IRP:** 50%

#### 2. SHAP Score (S_SHAP)

**Formule exacte selon m√©moire IRP:**
```
S_SHAP = mean(|SHAP_values|)
```

**Calcul d√©taill√©:**
1. Pour chaque instance `x_i` dans l'√©chantillon `X_sample`:
   - Calculer `SHAP_values_i = SHAP_explainer(x_i)`
2. Prendre valeur absolue: `|SHAP_values_i|`
3. Moyenner sur toutes les instances et tous les features:
   ```
   S_SHAP = mean(|SHAP_values|) sur toutes instances et features
   ```

**Normalisation:**
```
normalized_SHAP = min(S_SHAP / S_SHAP_max, 1.0)
```

**Pond√©ration selon m√©moire IRP:** 30%

#### 3. LIME Score (S_LIME)

**Formule exacte selon m√©moire IRP:**
```
S_LIME = mean(importance_scores)
```

**Calcul d√©taill√©:**
1. Pour chaque instance `x_i` dans l'√©chantillon `X_sample`:
   - Obtenir explication LIME: `explanation_i = LIME_explainer.explain_instance(x_i)`
   - Extraire scores d'importance: `importance_i = [score_j pour feature_j]`
   - Moyenner: `mean_importance_i = mean(|importance_i|)`
2. Moyenner sur toutes les instances:
   ```
   S_LIME = mean(mean_importance_i) pour tous les x_i
   ```

**Normalisation:**
```
normalized_LIME = min(S_LIME / S_LIME_max, 1.0)
```

**Pond√©ration selon m√©moire IRP:** 20%

### Score Combin√© Dimension 3

**Formule exacte selon m√©moire IRP:**
```
Dimension3_Score = 0.5 √ó I_native + 
                   0.3 √ó normalized_SHAP + 
                   0.2 √ó normalized_LIME
```

**Si une composante est manquante (None):**
- Les pond√©rations sont ajust√©es proportionnellement
- Exemple: Si SHAP manque ‚Üí `0.5 / 0.7 √ó I_native + 0.2 / 0.7 √ó normalized_LIME`

**Pond√©rations (somme = 1.0):**
- **50%**: Native Interpretability
- **30%**: SHAP Score
- **20%**: LIME Score

### Features N√©cessaires Dimension 3

- **Mod√®le entra√Æn√©**: Pour SHAP et LIME
- **Feature names**: Noms des features pour explications
- **√âchantillon de donn√©es**: `X_sample` (max 100 instances pour SHAP, 10 pour LIME)
- **Feature importances**: Pour mod√®les tree-based (I_native)

---

## üîÑ Normalisation pour Comparaison (AHP-TOPSIS)

### Normalisation Min-Max

Pour utiliser les scores dans AHP-TOPSIS, chaque dimension est normalis√©e entre [0, 1]:

```
D1_normalized = (D1_Score - D1_min) / (D1_max - D1_min)
D2_normalized = (D2_Score - D2_min) / (D2_max - D2_min)
D3_normalized = (D3_Score - D3_min) / (D3_max - D3_min)
```

O√π:
- `D1/D2/D3_min` = minimum parmi tous les algorithmes
- `D1/D2/D3_max` = maximum parmi tous les algorithmes

---

## üìä Features CICFlowMeter N√©cessaires (CIC-DDoS2019)

Selon le m√©moire IRP et la documentation CIC-DDoS2019, les **80 features standard** incluent:

### Features Temporelles (Flow Duration, IAT)
- `Flow Duration`
- `Flow IAT Mean`, `Flow IAT Std`, `Flow IAT Max`, `Flow IAT Min`
- `Fwd IAT Total`, `Fwd IAT Mean`, `Fwd IAT Std`, `Fwd IAT Max`, `Fwd IAT Min`
- `Bwd IAT Total`, `Bwd IAT Mean`, `Bwd IAT Std`, `Bwd IAT Max`, `Bwd IAT Min`
- `Active Mean`, `Active Std`, `Active Max`, `Active Min`
- `Idle Mean`, `Idle Std`, `Idle Max`, `Idle Min`

### Features Paquets Forward
- `Total Fwd Packets`
- `Total Length of Fwd Packets`
- `Fwd Packet Length Max`, `Fwd Packet Length Min`, `Fwd Packet Length Mean`, `Fwd Packet Length Std`
- `Fwd Packets/s`
- `Fwd Header Length`
- `Subflow Fwd Packets`, `Subflow Fwd Bytes`

### Features Paquets Backward
- `Total Backward Packets`
- `Total Length of Bwd Packets`
- `Bwd Packet Length Max`, `Bwd Packet Length Min`, `Bwd Packet Length Mean`, `Bwd Packet Length Std`
- `Bwd Packets/s`
- `Bwd Header Length`
- `Subflow Bwd Packets`, `Subflow Bwd Bytes`

### Features Globales
- `Flow Bytes/s`, `Flow Packets/s`
- `Min Packet Length`, `Max Packet Length`
- `Packet Length Mean`, `Packet Length Std`, `Packet Length Variance`
- `Average Packet Size`
- `Down/Up Ratio`

### Features Flags TCP
- `FIN Flag Count`, `SYN Flag Count`, `RST Flag Count`
- `PSH Flag Count`, `ACK Flag Count`, `URG Flag Count`
- `CWE Flag Count`, `ECE Flag Count`
- `Fwd PSH Flags`, `Bwd PSH Flags`
- `Fwd URG Flags`, `Bwd URG Flags`

### Features Segments TCP
- `Avg Fwd Segment Size`, `Avg Bwd Segment Size`
- `Fwd Avg Bytes/Bulk`, `Fwd Avg Packets/Bulk`, `Fwd Avg Bulk Rate`
- `Bwd Avg Bytes/Bulk`, `Bwd Avg Packets/Bulk`, `Bwd Avg Bulk Rate`
- `min_seg_size_forward`
- `act_data_pkt_fwd`

### Features Fen√™tre TCP
- `Init_Win_bytes_forward`
- `Init_Win_bytes_backward`

**Total: ~80 features CICFlowMeter** (exact nombre peut varier selon version)

---

## üìã Features Harmonis√©es (TON_IoT + CIC-DDoS2019)

### Features Communes (Mapping S√©mantique)

Selon l'harmonisation impl√©ment√©e:

1. **Features Exactes**: Colonnes pr√©sentes dans les deux datasets
2. **Features S√©mantiques**: Mapping bas√© sur similarit√© s√©mantique
   - `src_ip` ‚Üî `Src IP`, `Source IP`
   - `dst_ip` ‚Üî `Dst IP`, `Destination IP`
   - `src_port` ‚Üî `Src Port`, `Source Port`
   - `dst_port` ‚Üî `Dst Port`, `Destination Port`
   - `proto` ‚Üî `Protocol`, `Protocol Name`
   - `duration` ‚Üî `Flow Duration`
   - Etc.

### Features N√©cessaires pour √âvaluation

Pour chaque algorithme, le dataset harmonis√© doit contenir:
- **Features num√©riques**: Pour entra√Ænement des mod√®les
- **Label**: Colonne de classe (binaire ou multi-classes)
- **Dataset source**: Indicateur CIC-DDoS2019 vs TON_IoT (optionnel)

---

## ‚úÖ V√©rification d'Impl√©mentation

### Code Python - Dimension 1

```python
# src/evaluation_3d.py, lignes 258-268
is_binary = len(np.unique(y_test)) == 2
avg_method = 'binary' if is_binary else 'weighted'

f1 = f1_score(y_test, y_pred, average=avg_method)
precision = precision_score(y_test, y_pred, average=avg_method)
recall = recall_score(y_test, y_pred, average=avg_method)
accuracy = accuracy_score(y_test, y_pred)

# Dimension1_Score = f1 (comme m√©trique principale)
```

**‚úÖ Conforme**: Utilise `average='weighted'` pour multi-classes comme sp√©cifi√©.

### Code Python - Dimension 2

```python
# src/evaluation_3d.py, lignes 230-247
monitor = ResourceMonitor()
monitor.start()
model_clone.fit(X_train, y_train)
monitor.update()
resource_metrics = monitor.stop()

# resource_metrics contient:
# - training_time_seconds
# - memory_used_mb
# - peak_memory_mb

# Normalisation dans get_dimension_scores():
normalized_time = 1 - (time - time_min) / (time_max - time_min)
normalized_memory = 1 - (memory - memory_min) / (memory_max - memory_min)
Dimension2_Score = 0.6 * normalized_time + 0.4 * normalized_memory
```

**‚úÖ Conforme**: Pond√©rations 60/40 comme sp√©cifi√© dans m√©moire IRP.

### Code Python - Dimension 3

```python
# src/evaluation_3d.py, lignes 342-373
# Native interpretability (50%)
native = 1.0 if hasattr(model, 'feature_importances_') else 0.0
scores.append(native * 0.5)

# SHAP score (30%)
shap_norm = min(shap_score / 1.0, 1.0)
scores.append(shap_norm * 0.3)

# LIME score (20%)
lime_norm = min(lime_score / 1.0, 1.0)
scores.append(lime_norm * 0.2)

Dimension3_Score = sum(scores) / sum(weights)
```

**‚úÖ Conforme**: Pond√©rations 50/30/20 comme sp√©cifi√© dans m√©moire IRP.

---

## üìù R√©f√©rences

- **IRP M√©moire**: `_old/documents/IRP_FinalADE_v2.0ADE-2-1.pdf`
- **CIC-DDoS2019**: Sharafaldin et al. (2019), "Developing Realistic Distributed Denial of Service (DDoS) Attack Dataset and Taxonomy"
- **CICFlowMeter Features**: 80 features standard document√©es dans `datasets/cic_ddos2019/FEATURES_DESCRIPTION.md`
