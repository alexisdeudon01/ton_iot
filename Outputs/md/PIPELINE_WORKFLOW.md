# Pipeline Workflow - TON IoT DDoS Detection

## üîÑ WORKFLOW COMPLET

Ce workflow d√©finit la s√©quence exacte des √©tapes pour ex√©cuter le pipeline de d√©tection DDoS.

---

## Phase 0: Initialisation

### √âtape 0.1: Configuration Environment
```bash
# Activer environnement virtuel
source .toniot/bin/activate

# V√©rifier d√©pendances
python -c "import dask, torch, sklearn, pandas; print('‚úì Toutes d√©pendances OK')"
```

### √âtape 0.2: V√©rifier Datasets
```bash
# V√©rifier pr√©sence datasets
test -f datasets/ton_iot/train_test_network.csv && echo "‚úì ToN-IoT OK"
test -d datasets/cic_ddos2019 && echo "‚úì CIC-DDoS2019 OK"
```

### √âtape 0.3: Initialiser Monitoring
- D√©marrer SystemMonitor avec limite RAM 50%
- Initialiser Dask LocalCluster (2 workers, limite m√©moire 45% RAM totale)
- Cr√©er r√©pertoire output `rr/` (nettoy√© si existe)

**Crit√®re de Succ√®s**: Environment pr√™t, datasets accessibles, monitoring actif

---

## Phase 1: Chargement Donn√©es (Data Loading)

### √âtape 1.1: Initialiser DataLoader
```python
from src.new_pipeline.data_loader import RealDataLoader
loader = RealDataLoader(monitor=monitor, rr_dir=RR_DIR)
```

### √âtape 1.2: Charger Datasets (Lazy)
```python
# Op√©rations Dask lazy - pas de compute()
loader.load_datasets(
    ton_iot_path=TON_IOT_PATH,
    cic_ddos_dir=CIC_DDOS_DIR,
    sample_ratio=sample_ratio  # 0.001 en test-mode, 1.0 en prod
)
```

**Actions**:
- Lecture CSV ToN-IoT avec `dd.read_csv()` (lazy)
- Recherche r√©cursive fichiers CIC-DDoS2019 `**/*.csv`
- Mapping labels: `normal/BENIGN ‚Üí 0`, `ddos/autres ‚Üí 1`
- Harmonisation colonnes communes
- Ajout colonne `dataset` ('ton_iot' ou 'cic_ddos2019')
- Concat Dask (toujours lazy)

### √âtape 1.3: Profiling & Validation
```python
loader.profile_and_validate()
```

**Actions**:
- **UNIQUE compute()** sur `value_counts()` pour statistiques
- Split train/val/test (80/10/10) avec `random_split()` Dask
- G√©n√©ration graphique distribution classes
- Sauvegarde `rr/phase1_distribution.png`

**Crit√®re de Succ√®s**:
- Dask DataFrame charg√© (lazy)
- Splits cr√©√©s (train_ddf, val_ddf, test_ddf)
- Distribution classes affich√©e
- RAM < 60%

---

## Phase 2: Entra√Ænement (Training)

### √âtape 2.1: Extraction Features
```python
all_features = [c for c in train_ddf.columns 
                if c not in ["is_ddos", "label", "type", "dataset"]]
X_train = train_ddf[all_features]  # Reste lazy
y_train = train_ddf["is_ddos"]
```

### √âtape 2.2: It√©ration sur Algorithmes
Pour chaque algorithme dans `['LR', 'DT', 'RF', 'KNN', 'CNN', 'TabNet']`:

#### 2.2.1: Initialiser Trainer
```python
trainer = PipelineTrainer(random_state=42)
```

#### 2.2.2: Entra√Æner Mod√®le
```python
trainer.train_single(algo_name, X_train, y_train)
```

**Actions internes**:
- **Conversion Dask‚ÜíPandas**: `X_train.head(100000)`
  - ‚ö†Ô∏è **PROBL√àME ACTUEL**: Pas de contr√¥le RAM
  - üîß **√Ä IMPL√âMENTER**: MemoryAwareProcessor
- S√©lection colonnes num√©riques: `select_dtypes(include=[np.number])`
- Remplissage NaN: `fillna(0)`
- Entra√Ænement mod√®le sp√©cifique:
  - **Sklearn** (LR, DT, RF, KNN): `model.fit(X, y)`
  - **CNN**: Training loop PyTorch (20 epochs)
  - **TabNet**: `model.fit()` avec early stopping

#### 2.2.3: Sauvegarder R√©sultats
- Stocker dans `trainer.models[name]`
- Enregistrer `training_times[name]`
- Enregistrer `history[name]` (loss/accuracy par epoch)

#### 2.2.4: Visualisation
```python
trainer.plot_results(output_dir=RR_DIR)
```

**Graphiques g√©n√©r√©s**:
- `phase2_training_times.png` - Bar chart temps
- `phase2_convergence_{algo}.png` - Courbes loss/accuracy

**Crit√®re de Succ√®s**:
- 6 mod√®les entra√Æn√©s
- Historique training sauvegard√©
- Graphiques g√©n√©r√©s
- RAM < 70%

---

## Phase 3: Validation (Hyperparameter Tuning)

### √âtape 3.1: Initialiser Validator
```python
validator = PipelineValidator(models=trainer.models, random_state=42)
```

### √âtape 3.2: Tuning pour Chaque Algo
```python
validator.validate_tuning(X_val, y_val, RR_DIR, algo_name=algo)
```

**Actions**:
- **Conversion Dask‚ÜíPandas**: `X_val.head(50000)`
  - ‚ö†Ô∏è **PROBL√àME**: M√™me issue RAM
- Grid search sur hyperparam√®tres (d√©finis dans `config.py`)
- Pour chaque combinaison:
  - Fit mod√®le avec params
  - √âvaluation: Accuracy, F1, AUC
  - Log r√©sultats
- S√©lection meilleurs param√®tres (max F1)

### √âtape 3.3: Visualisation Tuning
**Graphiques g√©n√©r√©s**:
- `phase3_tuning_{algo}.png` - Variation param vs scores

**Crit√®re de Succ√®s**:
- Meilleurs params identifi√©s pour chaque algo
- Graphiques tuning sauvegard√©s
- RAM < 70%

---

## Phase 4: Explainabilit√© (XAI Validation)

### √âtape 4.1: Initialiser XAI Manager
```python
xai = XAIManager(rr_dir=RR_DIR)
```

### √âtape 4.2: √âvaluation XAI
```python
xai.validate_xai(models=trainer.models, X_test=X_test, y_test=y_test, algo_name=algo)
```

**Actions**:
- **Conversion Dask‚ÜíPandas**: `X_test.head(100)` (tr√®s petit sample)
  - ‚ö†Ô∏è **PROBL√àME**: M√™me pattern non s√©curis√©
- Pour chaque m√©thode XAI (`['SHAP', 'LIME', 'FI']`):
  - Mesurer **Fidelity**: Fid√©lit√© explicabilit√©
  - Mesurer **Stability**: Consistance explications
  - Mesurer **Complexity**: Sparsit√© features
  - Calculer **Composite Score** (pond√©r√©)

### √âtape 4.3: Visualisation XAI
**Graphiques g√©n√©r√©s**:
- `phase4_xai_metrics_{algo}.png` - Radar chart m√©triques XAI

**Crit√®re de Succ√®s**:
- Scores XAI calcul√©s (3 m√©triques √ó 3 m√©thodes)
- Meilleure m√©thode XAI s√©lectionn√©e
- Graphiques g√©n√©r√©s

---

## Phase 5: Test (Final Evaluation)

### √âtape 5.1: Initialiser Tester
```python
tester = PipelineTester(models=trainer.models, rr_dir=RR_DIR)
```

### √âtape 5.2: √âvaluation Finale
```python
tester.evaluate_all(X_test, y_test, algo_name=algo)
```

**Actions**:
- **Conversion Dask‚ÜíPandas**: `X_test.head(100000)`
  - ‚ö†Ô∏è **PROBL√àME**: M√™me issue RAM
- Pr√©dictions sur test set
- Calcul m√©triques:
  - Accuracy
  - F1-Score
  - Precision
  - Recall
  - AUC
- Analyse overfitting/underfitting:
  - Si F1 > 0.98: ‚ö†Ô∏è Alerte overfitting
  - Si F1 < 0.5: ‚ö†Ô∏è Alerte underfitting

### √âtape 5.3: Visualisations Finales
**Graphiques g√©n√©r√©s**:
- `phase5_metrics_synthesis.png` - Comparaison tous algos
- `phase5_final_report.txt` - Rapport textuel d√©taill√©

**Crit√®re de Succ√®s**:
- M√©triques finales calcul√©es (6 algos √ó 5 m√©triques)
- Rapport final g√©n√©r√©
- Graphiques comparatifs sauvegard√©s

---

## Phase 6: Finalisation & Rapports

### √âtape 6.1: Feature Analysis
```python
from src.core.feature_categorization import categorize_features
categorized = categorize_features(all_features)
```

**Actions**:
- Cat√©gorisation features (Flow ID, Basic Stats, Packet Length, etc.)
- Calcul scores par cat√©gorie
- Affichage verbose expert

### √âtape 6.2: G√©n√©ration Diagrammes
```python
from src.core.dependency_graph import generate_er_dependency_diagram
generate_er_dependency_diagram(RR_DIR / "pipeline_er_diagram.png")
```

### √âtape 6.3: Resource Monitoring
```python
monitor.plot_resource_consumption(str(RR_DIR / "resource_consumption.png"))
monitor.generate_timeline_heatmap(str(RR_DIR / "execution_timeline.png"))
```

**Graphiques g√©n√©r√©s**:
- `resource_consumption.png` - CPU/RAM par phase
- `execution_timeline.png` - Timeline ex√©cution

### √âtape 6.4: Analyses Suppl√©mentaires
**Graphiques g√©n√©r√©s**:
- `correlation_matrix.png` - Heatmap corr√©lations features
- `feature_importance_heatmap.png` - Top 30 features
- `category_metrics.png` - Scores cat√©gories

### √âtape 6.5: Cleanup
```python
monitor.stop_monitoring()
client.close()
cluster.close()
```

**Crit√®re de Succ√®s**:
- Tous graphiques g√©n√©r√©s dans `rr/`
- Rapport final complet
- Resources lib√©r√©es proprement

---

## üéØ R√âSUM√â WORKFLOW COMPLET

```mermaid
graph TD
    A[Phase 0: Init] --> B[Phase 1: Load Data]
    B --> C[Phase 2: Train Models]
    C --> D[Phase 3: Validate]
    D --> E[Phase 4: XAI]
    E --> F[Phase 5: Test]
    F --> G[Phase 6: Finalize]
    
    B -.->|Dask lazy| B1[ToN-IoT + CIC-DDoS2019]
    B1 -.->|1 compute| B2[Splits 80/10/10]
    
    C -->|Pour chaque algo| C1[LR]
    C -->|Pour chaque algo| C2[DT]
    C -->|Pour chaque algo| C3[RF]
    C -->|Pour chaque algo| C4[KNN]
    C -->|Pour chaque algo| C5[CNN]
    C -->|Pour chaque algo| C6[TabNet]
    
    C1 -.->|head 100k| C7[‚ö†Ô∏è RAM Issue]
    
    D -.->|head 50k| D1[‚ö†Ô∏è RAM Issue]
    E -.->|head 100| E1[‚ö†Ô∏è RAM Issue]
    F -.->|head 100k| F1[‚ö†Ô∏è RAM Issue]
    
    G --> H[‚úì Pipeline Complete]
```

---

## üìä POINTS DE CONTR√îLE (Checkpoints)

### Checkpoint 1: Apr√®s Phase 1
- ‚úÖ Datasets charg√©s (lazy)
- ‚úÖ Splits cr√©√©s
- ‚úÖ Distribution visualis√©e
- ‚úÖ RAM < 60%

### Checkpoint 2: Apr√®s Phase 2
- ‚úÖ 6 mod√®les entra√Æn√©s
- ‚úÖ Training times enregistr√©s
- ‚úÖ Convergence visualis√©e
- ‚úÖ RAM < 70%

### Checkpoint 3: Apr√®s Phase 3
- ‚úÖ Hyperparams optimis√©s
- ‚úÖ Tuning visualis√©
- ‚úÖ RAM < 70%

### Checkpoint 4: Apr√®s Phase 4
- ‚úÖ XAI √©valu√© (3 m√©thodes)
- ‚úÖ Scores calcul√©s
- ‚úÖ RAM < 70%

### Checkpoint 5: Apr√®s Phase 5
- ‚úÖ Test metrics finales
- ‚úÖ Rapport g√©n√©r√©
- ‚úÖ RAM < 80%

### Checkpoint 6: Fin Pipeline
- ‚úÖ Tous graphiques g√©n√©r√©s
- ‚úÖ Resources lib√©r√©es
- ‚úÖ Logs sauvegard√©s

---

## ‚ö†Ô∏è PROBL√àMES CONNUS & SOLUTIONS

### Probl√®me 1: Conversions Dask‚ÜíPandas Non Contr√¥l√©es
**Localisation**: Phases 2, 3, 4, 5

**Impact**: RAM peut monter √† 93%

**Solution √† Impl√©menter**: MemoryAwareProcessor
```python
# Au lieu de:
X_train_pd = X_train.head(100000)

# Utiliser:
X_train_pd = memory_mgr.safe_compute(X_train, "training_X")
```

### Probl√®me 2: Gestion Erreurs Basique
**Localisation**: Toutes phases

**Impact**: Erreurs silencieuses, pas de retry

**Solution √† Impl√©menter**: Framework exceptions personnalis√©es

### Probl√®me 3: Pas de R√©sumabilit√©
**Impact**: Si crash, tout recommencer

**Solution Future**: PipelineOrchestrator avec checkpoints

---

## üîÑ MODES D'EX√âCUTION

### Mode Test (--test-mode)
```bash
python3 main.py --test-mode
```
- Sample ratio: 0.1% des donn√©es
- Ex√©cution rapide (~5 minutes)
- RAM < 50%
- Pour d√©veloppement/debug

### Mode Partiel (--sample-ratio X)
```bash
python3 main.py --sample-ratio 0.5
```
- Sample ratio: 50% des donn√©es
- Ex√©cution moyenne (~30 minutes)
- RAM < 70%
- Pour validation interm√©diaire

### Mode Production (d√©faut)
```bash
python3 main.py
```
- Sample ratio: 100% des donn√©es
- Ex√©cution longue (~2-3 heures)
- RAM < 80%
- Pour r√©sultats finaux

---

## üìÅ OUTPUTS G√âN√âR√âS

Tous les fichiers sont dans `rr/`:

### Phase 1
- `phase1_distribution.png`

### Phase 2
- `phase2_training_times.png`
- `phase2_convergence_lr.png`
- `phase2_convergence_dt.png`
- `phase2_convergence_rf.png`
- `phase2_convergence_knn.png`
- `phase2_convergence_cnn.png`
- `phase2_convergence_tabnet.png`

### Phase 3
- `phase3_tuning_lr.png`
- `phase3_tuning_dt.png`
- `phase3_tuning_rf.png`
- `phase3_tuning_knn.png`

### Phase 4
- `phase4_xai_metrics_*.png`

### Phase 5
- `phase5_metrics_synthesis.png`
- `phase5_final_report.txt`

### Phase 6
- `resource_consumption.png`
- `execution_timeline.png`
- `correlation_matrix.png`
- `feature_importance_heatmap.png`
- `category_metrics.png`
- `pipeline_er_diagram.png`

---

## ‚úÖ CRIT√àRES DE SUCC√àS GLOBAL

- ‚úÖ Pipeline compl√®te sans crash
- ‚úÖ RAM reste < 80% en tout temps
- ‚úÖ 6 mod√®les entra√Æn√©s et √©valu√©s
- ‚úÖ Tous graphiques g√©n√©r√©s
- ‚úÖ Rapport final produit
- ‚úÖ Logs propres (pas d'erreurs)
- ‚úÖ Temps ex√©cution raisonnable
- ‚úÖ M√©triques coh√©rentes (F1 > 0.7)

---

Ce workflow d√©crit le flux complet actuel avec les points d'am√©lioration identifi√©s marqu√©s ‚ö†Ô∏è.
